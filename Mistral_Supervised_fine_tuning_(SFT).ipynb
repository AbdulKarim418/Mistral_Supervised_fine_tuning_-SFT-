{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9357hGFRqdi"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers[torch] datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxpq51gW_ySc"
   },
   "outputs": [],
   "source": [
    "!pip install -q bitsandbytes trl peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNJvtR1wGxHm",
    "outputId": "545b75a3-932e-4195-f74a-a6f3447f67de",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flash-attn in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.1.0+cu121)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.7.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from flash-attn) (23.2)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from flash-attn) (1.11.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhYvRDF25j59"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# based on config\n",
    "raw_datasets = load_dataset(\"HuggingFaceH4/ultrachat_200k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jX1sIK6X6Opi",
    "outputId": "f0ab2b40-6789-44c4-ece2-bd84e0d5fa65",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'messages'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['prompt', 'prompt_id', 'messages'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# remove this when done debugging\n",
    "indices = range(0,100)\n",
    "\n",
    "dataset_dict = {\"train\": raw_datasets[\"train_sft\"].select(indices),\n",
    "                \"test\": raw_datasets[\"test_sft\"].select(indices)}\n",
    "\n",
    "raw_datasets = DatasetDict(dataset_dict)\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P2XwVpT17TAb",
    "outputId": "8d441fee-4a0b-4310-9a30-86b4439e0609"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['prompt', 'prompt_id', 'messages'])\n"
     ]
    }
   ],
   "source": [
    "example = raw_datasets[\"train\"][0]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQ1sMda27Zj6",
    "outputId": "04b5ab19-2910-4f1b-91cb-3aece687e49b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user                :  These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\n",
      "On your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\n",
      "Your Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\n",
      "Does this feature apply to all sections of the theme or just specific ones as listed in the text material?\n",
      "assistant           :  This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.\n",
      "user                :  Can you guide me through the process of enabling the secondary image hover feature on my Collection pages and Featured Collections sections?\n",
      "assistant           :  Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\n",
      "\n",
      "1. Log in to your Shopify account and go to your Online Store.\n",
      "2. Click on Customize theme for the section-based theme you are using.\n",
      "3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\n",
      "4. With the section open, click on the section's setting (gear) icon in the top-left corner.\n",
      "5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\n",
      "6. If available, select 'Show secondary image on hover'.\n",
      "7. Save the changes and preview the Collection/Featured Collection page to see the effect.\n",
      "\n",
      "If you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.\n",
      "user                :  Can you provide me with a link to the documentation for my theme?\n",
      "assistant           :  I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.\n",
      "user                :  Can you confirm if this feature also works for the Quick Shop section of my theme?\n",
      "assistant           :  The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\n",
      "\n",
      "1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.\n"
     ]
    }
   ],
   "source": [
    "messages = example[\"messages\"]\n",
    "for message in messages:\n",
    "  role = message[\"role\"]\n",
    "  content = message[\"content\"]\n",
    "  print('{0:20}:  {1}'.format(role, content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvIfUqjK6ntu"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# set pad_token_id equal to the eos_token_id if not set\n",
    "if tokenizer.pad_token_id is None:\n",
    "  tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Set reasonable default for models without max length\n",
    "if tokenizer.model_max_length > 100_000:\n",
    "  tokenizer.model_max_length = 2048\n",
    "\n",
    "# Set chat template\n",
    "DEFAULT_CHAT_TEMPLATE = \"{% for message in messages %}\\n{% if message['role'] == 'user' %}\\n{{ '<|user|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'system' %}\\n{{ '<|system|>\\n' + message['content'] + eos_token }}\\n{% elif message['role'] == 'assistant' %}\\n{{ '<|assistant|>\\n'  + message['content'] + eos_token }}\\n{% endif %}\\n{% if loop.last and add_generation_prompt %}\\n{{ '<|assistant|>' }}\\n{% endif %}\\n{% endfor %}\"\n",
    "tokenizer.chat_template = DEFAULT_CHAT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44kIpOXa7Ep4",
    "outputId": "2895c3ad-d3c6-481f-8f96-64481dfbb977",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 17 of the processed training set:\n",
      "\n",
      "<|system|>\n",
      "</s>\n",
      "<|user|>\n",
      "Is it possible to have a combination of drawers, cupboards, and wine racks in the same sideboard?: Hand Made any size, any combination or drawers, cupboards, shelving, glazed, solid doors, wine racks.\n",
      "Stunning Oak top shown here but can be made with pine, Reclaimed Timber, Driftwood, Rustic Plank and beech tops also.\n",
      "4 Door Oslo sideboard as shown from £815. Can be made any size with your combination of drawers, cupboards, wine racks, shelving, door and plinth styles available, choice of different worktops (shown here with 20mm bull nose oak top) and finished in any Farrow and Ball colour of your choice.\n",
      "n.b prices are correct as of 01-05/16 but may be subject to change – please contact us for a quote based on your requirements, sizes and needs.</s>\n",
      "<|assistant|>\n",
      "Yes, it is possible to have a combination of drawers, cupboards, and wine racks in the same sideboard. The Hand Made sideboard can be customized to include any combination of these features, as well as shelving, glazed or solid doors, and different types of worktops. Prices for custom orders may vary, so interested customers should contact the seller for a quote based on their specific needs and requirements.</s>\n",
      "<|user|>\n",
      "Can you provide me with the contact information of the seller of the Hand Made sideboard? I would like to request a quote based on my specific needs and requirements.</s>\n",
      "<|assistant|>\n",
      "I do not have access to specific information about sellers or their contact details. However, if you have seen this sideboard online or in a physical store, you may be able to find the seller's contact information on their website or by reaching out to the store directly. Alternatively, you could search for similar handcrafted furniture makers in your area or online and reach out to them for custom orders.</s>\n",
      "<|user|>\n",
      "Can you provide me with some examples of the different worktops available for the Hand Made sideboard?</s>\n",
      "<|assistant|>\n",
      "Certainly, here are some examples of the different worktops available for the Hand Made sideboard:\n",
      "\n",
      "1. Oak - this is a classic and timeless choice that is known for its durability and natural beauty.\n",
      "2. Pine - a softer wood that has a warm, rustic feel and is often used in traditional or country-style interiors.\n",
      "3. Reclaimed Timber - this is wood that has been salvaged from old buildings, furniture or other sources, and can add character and history to a piece.\n",
      "4. Driftwood - a unique and striking option that is made from wood that has been washed up on shore and then treated and smoothed for use in furniture.\n",
      "5. Rustic Plank - this is a style of wood where individual planks of wood are combined to create a surface that has a rough-hewn, textured appearance.\n",
      "6. Beech - a smooth and hard-wearing option that has a uniform grain and a light, pale color.\n",
      "\n",
      "These are just a few examples of the different worktops available, and the options may vary based on the seller's availability and preferences.</s>\n",
      "\n",
      "Sample 29 of the processed training set:\n",
      "\n",
      "<|system|>\n",
      "</s>\n",
      "<|user|>\n",
      "Design a series of posters to promote bicycle commuting.</s>\n",
      "<|assistant|>\n",
      "I do not have the ability to create visual posters, but I can provide you with some taglines and content ideas that could be used in promoting bicycle commuting:\n",
      "\n",
      "1. \"riding a bike to work saves money, the environment, and your health!\"\n",
      "2. \"get exercise, fresh air, and beat traffic by riding your bike to work.\"\n",
      "3. \"join the bike-to-work movement! help reduce carbon emissions and promote sustainable living, one pedal stroke at a time!\"\n",
      "4. \"who needs a gym when you can burn calories on your bike commute?\"\n",
      "5. \"experience the freedom and joy of cycling while reducing congestion on the roads.\"\n",
      "6. \"riding a bike is good for your body, mind, and wallet. Give it a try!\"\n",
      "7. \"less time stuck in traffic. More time enjoying the open road. Ride to work and feel alive!\"\n",
      "8. \"reduce your carbon footprint and get in shape by biking to work. It’s a win-win for you and the planet!\"\n",
      "9. \"bike to work and explore your city in a new way. Discover hidden treasures and enjoy the scenery.\"\n",
      "10. \"biking to work is not just a mode of transportation. It's a lifestyle that promotes health, wellness, and sustainability.\"</s>\n",
      "<|user|>\n",
      "Could you possibly provide me with more information on the benefits of bike commuting, like specific health benefits or the environmental impact?</s>\n",
      "<|assistant|>\n",
      "Certainly! Here are some additional benefits of bike commuting that you could use in your posters or other promotional materials:\n",
      "\n",
      "1. Health benefits: Biking is a great way to stay active, which can have numerous health benefits such as reducing the risk of obesity, heart disease, stroke, and type 2 diabetes. It can also improve mental health by reducing stress levels. 2. Environmental impact: Bike commuting is a sustainable transportation option that does not contribute to air pollution, noise pollution, or greenhouse gas emissions that are associated with motorized vehicles. By choosing to bike instead of drive, you can help to reduce your carbon footprint and protect the environment. 3. Economic benefits: Biking can be a more cost-effective mode of transportation. By avoiding the cost of gas, insurance, and car maintenance, you can save money in the long run. Additionally, some cities may offer incentives or tax credits to encourage bike commuting. 4. Improved productivity: Biking to work can help to increase alertness and productivity by providing a morning exercise routine that can help you feel more energized throughout the day. 5. Free parking: Unlike cars, bikes do not require parking spaces or fees, which means that you can save money and time by not having to search for parking. These are just a few of the many benefits of biking to work. By highlighting these benefits, you can help to encourage more people to give bike commuting a try.</s>\n",
      "<|user|>\n",
      "Could you provide me with some statistics to back up these points?</s>\n",
      "<|assistant|>\n",
      "Certainly! Here are some statistics that you could use to support the benefits of bike commuting in your posters:\n",
      "\n",
      "1. Health benefits:\n",
      "   - According to the World Health Organization, physical inactivity is the fourth leading risk factor for global mortality. Regular physical activity, such as cycling, can reduce the risk of non-communicable diseases, such as heart disease and stroke, by up to 30%. - Cycling for just 30 minutes per day can burn up to 500 calories. 2. Environmental impact:\n",
      "   - According to the European Cyclists' Federation, a person cycling 10 km to work and back every day can save over 1,500 kg of CO2 emissions per year, compared to traveling by car. - The Union of Concerned Scientists estimates that if Americans replaced just one car trip per day with a bike ride, it would save 2 billion gallons of gas and reduce carbon emissions by 22 billion pounds per year. 3. Economic benefits:\n",
      "   - According to the Bicycle Commuter Act, a tax credit of up to $240 per year is available for employees who bike to work. - A study from the University of California found that employers can save up to $7,000 per year for each employee who bikes to work instead of driving. 4. Improved productivity:\n",
      "   - A study from the University of Bristol found that employees who ride their bikes to work are less likely to experience a dip in concentration and energy mid-morning and mid-afternoon, leading to improved productivity. 5. Free parking:\n",
      "   - According to the National Association of City Transportation Officials, a single car parking spot can cost between $5,000 and $50,000 to build and maintain, whereas a bike parking facility can support dozens of bikes at a fraction of the cost. These statistics can help to make your posters more compelling and informative, and they can also make it easier for readers to understand the potential benefits of bike commuting.</s>\n",
      "<|user|>\n",
      "Could you also provide some tips for bike commuting beginners, like what gear they may need or safety precautions they should take?</s>\n",
      "<|assistant|>\n",
      "Sure! Here are some tips for beginners who want to start bike commuting:\n",
      "\n",
      "1. Get the right gear: Good gear can make your ride more comfortable and safer. You will need a helmet, a sturdy bike lock or secure parking space, and clothing appropriate for the weather conditions. If you are biking at night or in low-light conditions, be sure to wear reflective clothing or add reflective tape to your bike or helmet. 2. Plan your route: Research your route and choose one that is safe and convenient for your skill level. Consider bike-friendly roads or bike lanes, and avoid busy streets or heavy traffic areas. Many cities have online resources or maps of bike routes that you can use to plan your commute. 3. Practice safety precautions: Always obey traffic laws, including stop signs and traffic signals. Use hand signals to indicate when you are turning or stopping. Be visible, especially in low-light conditions, by using lights and reflective clothing. Always wear a helmet to protect your head. 4. Start slowly: If you are new to biking or haven't ridden in a while, start with short rides and gradually increase your distance and speed. Be patient with yourself and don't push yourself too hard. 5. Be prepared: Bring a small toolkit with you, including a spare tube, tire levers, and a pump. Make sure your bike is in good working condition before you set out on a ride. 6. Consider taking a bike safety class: Many cities offer bike safety classes that can help you learn the rules of the road and improve your cycling skills. Following these tips can help make your bike commute more enjoyable, safe, and easy.</s>\n",
      "\n",
      "Sample 61 of the processed training set:\n",
      "\n",
      "<|system|>\n",
      "</s>\n",
      "<|user|>\n",
      "What kind of collaborative work is expected of the Art Teacher at The School of Arts and Sciences?\n",
      "Generate according to: The School of Arts and Sciences, at 3208 Thomasville Rd, Tallahassee, FL is seeking applications for a Kindergarten-8th grade Art Teacher to teach in a multi-aged classroom. Applicants should be able to plan and execute rigorous, teacher created, hands-on thematic and project based lessons. They will also implement and support instruction and assessment practices for a diverse group of students that reflect the Florida Standards and the principles of their Charter. Also, they will work collaboratively with a diverse group of school colleagues, parents, community members and others to support and implement the goals of the school. Portfolio assessment experience. Salary and benefits commensurate with education and experience; eligible for benefits.\n",
      "If interested, please submit a resume and cover letter with SAST ART TEACHER in the subject line by May 11, 2018 to Eirin Lombardo, Principal at lombardoe@leonschools.net.</s>\n",
      "<|assistant|>\n",
      "As an Art Teacher at The School of Arts and Sciences, the successful applicant is expected to work collaboratively with a diverse group of school colleagues, parents, community members, and others. This includes working with other teachers and staff to integrate art into other subjects such as history, literature, and science. The applicant should also be able to participate in meetings and professional development activities that aim to improve instruction for students.\n",
      "\n",
      "The Art Teacher is expected to create and deliver rigorous, teacher-created, hands-on thematic and project-based lessons that reflect the Florida Standards and the principles of the school’s Charter. The successful applicant should be able to plan and execute lessons that are appropriate for a multi-aged classroom that includes Kindergarten to 8th grade students. They should be able to use various techniques, tools, and materials to develop students’ artistic abilities.\n",
      "\n",
      "The Art Teacher should also have experience in portfolio assessment and be able to implement and support instruction and assessment practices for a diverse group of students. They should be able to provide feedback to students on their artwork and help them reflect on their growth and development.\n",
      "\n",
      "In summary, the Art Teacher at The School of Arts and Sciences is expected to work collaboratively, plan and deliver rigorous, hands-on lessons, support instruction and assessment practices, work with a diverse group of students, and have experience in portfolio assessment.</s>\n",
      "<|user|>\n",
      "Can you give me some examples of how the Art Teacher at The School of Arts and Sciences can integrate art into other subjects?</s>\n",
      "<|assistant|>\n",
      "Certainly! Here are some examples of how the Art Teacher at The School of Arts and Sciences can integrate art into other subjects:\n",
      "\n",
      "1. History - The Art Teacher can teach students about a specific historical period and then have them create artwork that reflects the time period. For example, students could create Egyptian hieroglyphs or Greek pottery.\n",
      "\n",
      "2. Literature - The Art Teacher can have students create artwork based on a book they have read. For example, students could create a painting or sculpture based on characters from a book.\n",
      "\n",
      "3. Science - The Art Teacher can have students create artwork that reflects scientific concepts. For example, students could create a sculpture of an atom or create an ecosystem painting.\n",
      "\n",
      "4. Mathematics - The Art Teacher can teach students the principles of symmetry and have them create symmetrical artwork. For example, students could create a symmetrical mandala.\n",
      "\n",
      "5. Social Studies - The Art Teacher can have students create maps or globes to learn about geography. Students can also create posters or collages about different cultures.\n",
      "\n",
      "These are just a few examples, but there are many ways the Art Teacher can integrate art into other subjects to enhance students’ learning.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "def apply_chat_template(example, tokenizer):\n",
    "    messages = example[\"messages\"]\n",
    "    # We add an empty system message if there is none\n",
    "    if messages[0][\"role\"] != \"system\":\n",
    "        messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "\n",
    "    return example\n",
    "\n",
    "column_names = list(raw_datasets[\"train\"].features)\n",
    "raw_datasets = raw_datasets.map(apply_chat_template,\n",
    "                                num_proc=cpu_count(),\n",
    "                                fn_kwargs={\"tokenizer\": tokenizer},\n",
    "                                remove_columns=column_names,\n",
    "                                desc=\"Applying chat template\",)\n",
    "\n",
    "# create the splits\n",
    "train_dataset = raw_datasets[\"train\"]\n",
    "eval_dataset = raw_datasets[\"test\"]\n",
    "\n",
    "for index in random.sample(range(len(raw_datasets[\"train\"])), 3):\n",
    "  print(f\"Sample {index} of the processed training set:\\n\\n{raw_datasets['train'][index]['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L_tvjW-Y-uBT",
    "outputId": "631fdd9f-c4ac-4824-cf6f-7aded04ea5ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrSQuIyu8Rt1"
   },
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# specify how to quantize the model\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=\"torch.bfloat16\",\n",
    ")\n",
    "device_map = {\"\": torch.cuda.current_device()} if torch.cuda.is_available() else None\n",
    "\n",
    "model_kwargs = dict(\n",
    "    attn_implementation=\"flash_attention_2\", # set this to True if your GPU supports it (Flash Attention drastically speeds up model computations)\n",
    "    torch_dtype=\"auto\",\n",
    "    use_cache=False, # set to False as we're going to use gradient checkpointing\n",
    "    device_map=device_map,\n",
    "    quantization_config=quantization_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158,
     "referenced_widgets": [
      "ce1f77a753394dc5a25e5470fac18560",
      "7bb6256651a142eabc61984dfe5d379f",
      "12154fd312434260b7f6779a857e1a82",
      "2e44353a59c4480a8e877d842ad16061",
      "abdc9ab22ec049938855373effaf1504",
      "090b3eaf7d2548ee867fc7d9ddf67523",
      "2f2dd26e18ca47dfae4ff33dbb869c0f",
      "e5f6717710074184b78c30f4668be2b5",
      "222a8b16e19140269c44afffbca96865",
      "c3fd940f4dd34ce5b7a462e2bf6f1f71",
      "6264e61a163b4a5dbdb854f7e2ff3056"
     ]
    },
    "id": "W80YklLm_xAY",
    "outputId": "ced661c2-d638-4b4e-bc62-48ca240e2943"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:158: UserWarning: You passed a model_id to the SFTTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1f77a753394dc5a25e5470fac18560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:282: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# path where the Trainer will save its checkpoints and logs\n",
    "output_dir = 'data/zephyr-7b-sft-lora'\n",
    "\n",
    "# based on config\n",
    "training_args = TrainingArguments(\n",
    "    fp16=True, # specify bf16=True instead when training on GPUs that support bf16\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    gradient_accumulation_steps=128,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    learning_rate=2.0e-05,\n",
    "    log_level=\"info\",\n",
    "    logging_steps=5,\n",
    "    logging_strategy=\"steps\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    max_steps=-1,\n",
    "    num_train_epochs=1,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_eval_batch_size=1, # originally set to 8\n",
    "    per_device_train_batch_size=1, # originally set to 8\n",
    "    # push_to_hub=True,\n",
    "    # hub_model_id=\"zephyr-7b-sft-lora\",\n",
    "    # hub_strategy=\"every_save\",\n",
    "    # report_to=\"tensorboard\",\n",
    "    save_strategy=\"no\",\n",
    "    save_total_limit=None,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# based on config\n",
    "peft_config = LoraConfig(\n",
    "        r=64,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "        model=model_id,\n",
    "        model_init_kwargs=model_kwargs,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        dataset_text_field=\"text\",\n",
    "        tokenizer=tokenizer,\n",
    "        packing=True,\n",
    "        peft_config=peft_config,\n",
    "        max_seq_length=tokenizer.model_max_length,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgEnI5KMIwyt"
   },
   "outputs": [],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Ai5jXhJBMsj"
   },
   "outputs": [],
   "source": [
    "metrics = train_result.metrics\n",
    "max_train_samples = training_args.max_train_samples if training_args.max_train_samples is not None else len(train_dataset)\n",
    "metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yiRvmsSkyubH"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(output_dir, load_in_4bit=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hkacv5PvBOvE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
    "]\n",
    "\n",
    "# prepare the messages for the model\n",
    "input_ids = tokenizer.apply_chat_template(messages, truncation=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# inference\n",
    "outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95\n",
    ")\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO3+qbEnufQLsoi2VvofRJ8",
   "gpuType": "T4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "090b3eaf7d2548ee867fc7d9ddf67523": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12154fd312434260b7f6779a857e1a82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5f6717710074184b78c30f4668be2b5",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_222a8b16e19140269c44afffbca96865",
      "value": 2
     }
    },
    "222a8b16e19140269c44afffbca96865": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2e44353a59c4480a8e877d842ad16061": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3fd940f4dd34ce5b7a462e2bf6f1f71",
      "placeholder": "​",
      "style": "IPY_MODEL_6264e61a163b4a5dbdb854f7e2ff3056",
      "value": " 2/2 [00:09&lt;00:00,  4.59s/it]"
     }
    },
    "2f2dd26e18ca47dfae4ff33dbb869c0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6264e61a163b4a5dbdb854f7e2ff3056": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7bb6256651a142eabc61984dfe5d379f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_090b3eaf7d2548ee867fc7d9ddf67523",
      "placeholder": "​",
      "style": "IPY_MODEL_2f2dd26e18ca47dfae4ff33dbb869c0f",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "abdc9ab22ec049938855373effaf1504": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3fd940f4dd34ce5b7a462e2bf6f1f71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce1f77a753394dc5a25e5470fac18560": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7bb6256651a142eabc61984dfe5d379f",
       "IPY_MODEL_12154fd312434260b7f6779a857e1a82",
       "IPY_MODEL_2e44353a59c4480a8e877d842ad16061"
      ],
      "layout": "IPY_MODEL_abdc9ab22ec049938855373effaf1504"
     }
    },
    "e5f6717710074184b78c30f4668be2b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
